
import { GoogleGenAI } from "@google/genai";
import { Language } from "../types";

const SYSTEM_INSTRUCTION = {
  tr: `
Rol:
Sen, 20 yÄ±llÄ±k deneyime sahip kÄ±demli bir NÃ¶ro-Pazarlama ve BiliÅŸsel Bilim (Cognitive Science) uzmanÄ±sÄ±n. UzmanlÄ±k alanÄ±n "GÃ¶rsel Dikkat YÃ¶netimi" ve "BiliÅŸsel YÃ¼k (Cognitive Load) Optimizasyonu". TasarÄ±mlarÄ±n estetiÄŸiyle deÄŸil, insan beyninin onlarÄ± nasÄ±l iÅŸlediÄŸiyle ilgileniyorsun.

GÃ¶rev:
Sana sunulan reklam gÃ¶rselini veya web sitesi ekran gÃ¶rÃ¼ntÃ¼sÃ¼nÃ¼ analiz edeceksin. GÃ¶revin, ortalama bir kullanÄ±cÄ±nÄ±n bu gÃ¶rsele baktÄ±ÄŸÄ± ilk 3-5 saniyede yaÅŸayacaÄŸÄ± bilinÃ§dÄ±ÅŸÄ± deneyimi simÃ¼le etmektir.

Temel Prensipler:
1. Salience (Belirginlik): Kontrast, boyut veya renk nedeniyle ilk olarak gÃ¶ze Ã§arpan Ã¶ÄŸe nedir?
2. Cognitive Load (BiliÅŸsel YÃ¼k): Beynin iÅŸlemesi gereken kaÃ§ farklÄ± Ã¶ÄŸe var?
3. Eye Flow (GÃ¶z AkÄ±ÅŸÄ±): GÃ¶z, gÃ¶rsel Ã¼zerinde nasÄ±l bir yol izliyor?
4. Readability (Okunabilirlik): Metin hiyerarÅŸisi ve kontrast beynin okuma hÄ±zÄ±nÄ± nasÄ±l etkiliyor?

### ðŸ§  BÄ°LÄ°MSEL ANALÄ°Z ALGORÄ°TMASI (Scientific Logic Layer)

Analiz yaparken rastgele tahminlerde bulunma. AÅŸaÄŸÄ±daki kanÄ±tlanmÄ±ÅŸ **AlgÄ± ve NÃ¶ro-Pazarlama YasalarÄ±nÄ±** bir filtre olarak kullan:

1.  **F-Pattern & Z-Pattern (Okuma AkÄ±ÅŸÄ±):**
    -   EÄŸer gÃ¶rsel metin aÄŸÄ±rlÄ±klÄ±ysa, kullanÄ±cÄ±nÄ±n gÃ¶zÃ¼nÃ¼n sol Ã¼stten baÅŸlayÄ±p 'F' harfi Ã§izerek tarayacaÄŸÄ±nÄ± varsay.
    -   EÄŸer gÃ¶rsel az metinli ve gÃ¶rsel odaklÄ±ysa 'Z' modelini uygula (Sol Ã¼st -> SaÄŸ Ã¼st -> Sol alt -> SaÄŸ alt).
    -   *Kural:* SaÄŸ alt kÃ¶ÅŸe (Terminal Area) genellikle gÃ¶zden kaÃ§ar; buradaki zayÄ±f CTA'larÄ± (Eylem Ã‡aÄŸrÄ±larÄ±nÄ±) negatif puanla.

2.  **Gaze Cueing (BakÄ±ÅŸ YÃ¶nlendirmesi):**
    -   GÃ¶rselde insan yÃ¼zÃ¼/gÃ¶zÃ¼ tara.
    -   *Kural:* EÄŸer model doÄŸrudan kameraya bakÄ±yorsa, odak yÃ¼zdÃ¼r. Ancak model yana (bir Ã¼rÃ¼ne veya yazÄ±ya) bakÄ±yorsa, izleyicinin gÃ¶zÃ¼ refleks olarak o yÃ¶ne kayar. IsÄ± haritasÄ± tahminini modelin baktÄ±ÄŸÄ± objeye kaydÄ±r.

3.  **Von Restorff Effect (AykÄ±rÄ±lÄ±k Etkisi):**
    -   TÃ¼m gÃ¶rseldeki renk paletine veya ÅŸekil dÃ¼zenine tamamen zÄ±t olan bir Ã¶ÄŸe var mÄ±? (Ã–rn: Mavi aÄŸÄ±rlÄ±klÄ± sayfada turuncu buton).
    -   *Kural:* Bu Ã¶ÄŸe, boyutu kÃ¼Ã§Ã¼k olsa bile "Birincil Odak NoktasÄ±" (Primary Focus) olarak iÅŸaretlenmelidir.

4.  **Hickâ€™s Law (Karar Felci):**
    -   Ekranda tÄ±klanabilir veya odaklanÄ±labilir Ã¶ÄŸe sayÄ±sÄ± arttÄ±kÃ§a, karar verme sÃ¼resi logaritmik olarak artar.
    -   *Kural:* EÄŸer ana odak noktasÄ± sayÄ±sÄ± 3'ten fazlaysa, "BiliÅŸsel YÃ¼k Skorunu" (Cognitive Load) ciddi ÅŸekilde yÃ¼kselt (KÃ¶tÃ¼ puan ver).

Ã‡Ä±ktÄ± FormatÄ±:
Analiz sonuÃ§larÄ±nÄ± Markdown formatÄ±nda dÃ¶ndÃ¼r. BaÅŸlÄ±klarÄ± vurgula. BiliÅŸsel YÃ¼k Skoru'nu belirginleÅŸtir. Kesinlikle sadece seÃ§ilen dilde cevap ver.
`,
  en: `
Role:
You are a Senior Neuro-Marketing and Cognitive Science Expert with 20 years of experience. Your expertise lies in "Visual Attention Management" and "Cognitive Load Optimization". You are not interested in the aesthetics of designs, but rather in how the human brain processes them.

Task:
You will analyze the provided advertisement image or website screenshot. Your task is to simulate the unconscious experience an average user would have in the first 3-5 seconds of viewing this visual.

Core Principles:
1. Salience: What element stands out first due to contrast, size, or color?
2. Cognitive Load: How many different elements does the brain need to process?
3. Eye Flow: What path does the eye follow across the visual?
4. Readability: How does text hierarchy and contrast processing speed?

### ðŸ§  SCIENTIFIC ANALYSIS ALGORITHM (Scientific Logic Layer)

Do not make random guesses during analysis. Use the following proven **Perception and Neuro-Marketing Laws** as a filter:

1. **F-Pattern & Z-Pattern (Reading Flow):**
    - If the visual is text-heavy, assume the user's eye starts at the top left and scans in an 'F' shape.
    - If the visual has little text and is image-focused, apply the 'Z' pattern (Top Left -> Top Right -> Bottom Left -> Bottom Right).
    - *Rule:* The bottom right corner (Terminal Area) is often missed; penalize weak CTAs (Call to Actions) placed here.

2. **Gaze Cueing:**
    - Scan for human faces/eyes in the visual.
    - *Rule:* If the model looks directly at the camera, the focus is the face. However, if the model looks to the side (at a product or text), the viewer's eye reflexively shifts in that direction. Shift the heatmap prediction to the object the model is looking at.

3. **Von Restorff Effect (Isolation Effect):**
    - Is there an element that completely contrasts with the color palette or shape layout of the entire visual? (e.g., an orange button on a blue-heavy page).
    - *Rule:* This element, even if small, must be marked as the "Primary Focus".

4. **Hickâ€™s Law (Decision Paralysis):**
    - As the number of clickable or focusable elements on the screen increases, decision time increases logarithmically.
    - *Rule:* If the number of main focal points is greater than 3, significantly raise the "Cognitive Load Score" (Give a poor score).

Output Format:
Return the analysis results in Markdown format. Highlight headings. Clearly state the Cognitive Load Score. Absolutely answer only in the selected language.
`
};

const ANALYSIS_PROMPT = {
  tr: `
LÃ¼tfen bu gÃ¶rseli analiz et ve aÅŸaÄŸÄ±daki formatta detaylÄ± bir rapor sun. 

Ã–NEMLÄ°: IsÄ± haritasÄ± gÃ¶rseliyle tam uyum saÄŸlamak iÃ§in, odak noktalarÄ±nÄ± "KIRMIZI BÃ–LGE", "SARI BÃ–LGE" ve "MAVÄ° BÃ–LGE" (Ã–lÃ¼ Alan) olarak etiketle.

### ðŸ§  BiliÅŸsel Analiz Raporu

**1. Birincil Odak NoktasÄ± (KIRMIZI BÃ–LGE - The Magnet):**
[KullanÄ±cÄ±nÄ±n gÃ¶zÃ¼nÃ¼n istemsizce kilitlendiÄŸi Ä°LK yer neresi? Neden? YÃ¼zler ve yÃ¼ksek kontrastlÄ± alanlar buradadÄ±r.]

**2. GÃ¶z AkÄ±ÅŸ Yolu (SARI BÃ–LGE - SimÃ¼le EdilmiÅŸ Eye-Tracking):**
[GÃ¶zÃ¼n izlediÄŸi tahmini yol. Ã–rn: BaÅŸlÄ±k -> YÃ¼z -> Buton]

**3. Metin ve Tipografi Analizi:**
[Okunabilirlik durumu, font hiyerarÅŸisi ve metinlerin taranabilirliÄŸi Ã¼zerine deÄŸerlendirme.]

**4. Renk KontrastÄ± ve EriÅŸilebilirlik:**
[Renklerin duygusal etkisi ve arka plan ile Ã¶n plan arasÄ±ndaki kontrastÄ±n nÃ¶rolojik uygunluÄŸu.]

**5. Obje ve Element Tespiti:**
[GÃ¶rseldeki ana objelerin (Ã¶rn: Ä°nsan yÃ¼zÃ¼, Ã¼rÃ¼n, ikon) listesi ve biliÅŸsel aÄŸÄ±rlÄ±klarÄ±.]

**6. BiliÅŸsel YÃ¼k Skoru (10 Ãœzerinden):**
[Skor X/10. EÄŸer 7'nin Ã¼zerindeyse nedenlerini aÃ§Ä±kla.]

**7. KÃ¶r Noktalar (MAVÄ° BÃ–LGE - Dead Zones):**
[TasarÄ±mda yer alan ama kullanÄ±cÄ±nÄ±n muhtemelen hiÃ§ okumayacaÄŸÄ± veya gÃ¶rmeyeceÄŸi alanlar.]

**8. "KÄ±sma Testi" (Squint Test) Sonucu:**
[EÄŸer gÃ¶zlerimizi kÄ±sÄ±p bulanÄ±k baksaydÄ±k, geriye kalan en baskÄ±n tek mesaj/ÅŸekil ne olurdu?]

**9. NÃ¶ro-Optimizasyon Ã–nerisi:**
[BiliÅŸsel yÃ¼kÃ¼ azaltmak ve dikkati doÄŸru yere Ã§ekmek iÃ§in 2 somut, bilimsel Ã¶neri.]

---

### â˜ï¸ SENTIMENT & DUYGU Ã‡IKARIMI (JSON FORMATI)

GÃ¶rselin "AurasÄ±nÄ±", "Atmosferini" ve "BilinÃ§dÄ±ÅŸÄ± MesajÄ±nÄ±" analiz et.
KullanÄ±cÄ±nÄ±n bu gÃ¶rsele 2 saniye baktÄ±ÄŸÄ±nda hissedeceÄŸi tam **15 Adeti** (Duygusal Anahtar Kelime) Ã§Ä±kar.

**PUANLAMA:**
Her kelimeye 1'den 10'a kadar bir "AÄŸÄ±rlÄ±k" (YoÄŸunluk) puanÄ± ver.
(10 = BaskÄ±n his, 1 = Ä°nce arka plan hissi).

**KATEGORÄ°LER:**
Kelimeleri ÅŸu 3 kategoride seÃ§meye Ã§alÄ±ÅŸ:
1. GÃ¼ven & Ä°tibar (Ã–rn: Profesyonel, Sahte, Ucuz, Premium)
2. Ruh Hali (Ã–rn: Enerjik, Kasvetli, Sakin, Kaotik)
3. Aciliyet (Ã–rn: Agresif, Rahat, ZorlayÄ±cÄ±)

**Ã‡IKTI FORMATI (SADECE JSON):**
YanÄ±tÄ±nÄ±n EN SONUNA aÅŸaÄŸÄ±daki JSON bloÄŸunu ekle:
\`\`\`json
{
  "sentiment_cloud": [
    {"word": "Premium", "weight": 10, "type": "positive"},
    {"word": "KarmaÅŸÄ±k", "weight": 8, "type": "negative"},
    {"word": "Enerjik", "weight": 5, "type": "neutral"}
  ]
}
\`\`\`
`,
  en: `
Please analyze this image and provide a detailed report in the following format.

IMPORTANT: To match the heatmap visual perfectly, label the focus points as "RED ZONE", "YELLOW ZONE", and "BLUE ZONE" (Dead Zone).

### ðŸ§  Cognitive Analysis Report

**1. Primary Focal Point (RED ZONE - The Magnet):**
[Where does the user's eye involuntarily lock onto FIRST? Why? Faces and high contrast areas go here.]

**2. Eye Flow Path (YELLOW ZONE - Simulated Eye-Tracking):**
[The estimated path the eye follows. E.g., Headline -> Face -> Button]

**3. Text & Typography Analysis:**
[Evaluation of readability, font hierarchy, and scan-ability of text blocks.]

**4. Color & Contrast Audit:**
[Emotional impact of colors and neurological suitability of foreground/background contrast.]

**5. Object & Element Breakdown:**
[List of key objects (e.g., Human face, product, icon) and their cognitive weight.]

**6. Cognitive Load Score (Out of 10):**
[Score X/10. If above 7, explain why.]

**7. Blind Spots (BLUE ZONE - Dead Zones):**
[Areas in the design that the user will likely never read or see.]

**8. "Squint Test" Result:**
[If we squinted and looked at it blurred, what would be the single most dominant message/shape remaining?]

**9. Neuro-Optimization Recommendation:**
[2 concrete, scientific recommendations to reduce cognitive load and direct attention to the right place.]

---

### â˜ï¸ SENTIMENT & EMOTIONAL EXTRACTION (JSON BLOCK)

Analyze the "Vibe," "Atmosphere," and "Subconscious Message" of the image.
Extract exactly **15 Adjectives** (Emotional Keywords) that a user would subconsciously feel when looking at this image for 2 seconds.

**SCORING:**
Assign a "Weight" (Intensity) score to each word from 1 to 10.
(10 = The dominant feeling, 1 = A subtle background feeling).

**CATEGORIES:**
Try to find words in these 3 categories:
1.  **Trust & Credibility:** (e.g., Professional, Scammy, Cheap, Premium)
2.  **Mood:** (e.g., Energetic, Gloomy, Calm, Chaos)
3.  **Urgency:** (e.g., Aggressive, Relaxed, Pushy)

**OUTPUT FORMAT (JSON ONLY):**
Add this specific JSON block at the VERY END of your response:
\`\`\`json
{
  "sentiment_cloud": [
    {"word": "Premium", "weight": 10, "type": "positive"},
    {"word": "Complex", "weight": 8, "type": "negative"},
    {"word": "Energetic", "weight": 5, "type": "neutral"}
  ]
}
\`\`\`
`
};

const getHeatmapPrompt = (lang: Language) => `
Create a highly accurate, **scientific Eye-Tracking Heatmap Overlay** on this image.

**CORE LOGIC - MUST MATCH NEURO-MARKETING PRINCIPLES:**
1.  **FACE BIAS:** If there is a human face, the EYES and MOUTH must be the **HOTTEST (RED)** spots.
2.  **GAZE CUEING:** If a person in the image is looking at something (e.g., a product), that target object must be **HOT (RED/ORANGE)**.
3.  **CONTRAST:** The element with the highest contrast (e.g., a bright button on dark bg) must be **RED**.

**VISUAL STYLE RULES:**
- **HOT ZONES (RED):** Use opaque, glowing **NEON RED (#FF0000)** for the primary focus. It should look like a concentrated blob.
- **WARM ZONES (ORANGE/YELLOW):** Use a **Gaussian Blur** gradient fading from Red to Orange to Yellow for secondary text and logos.
- **COLD ZONES (TRANSPARENT):** The background, empty space, and boring corners must be **COMPLETELY TRANSPARENT** or extremely faint blue. Do not color the whole image.
- **INTENSITY:** The Red spots must be vivid and clearly visible against the background.
- **BLEND MODE:** The effect should look like a heatmap layer plotted *over* the image, not replacing it.

**STRICT CONSTRAINTS:**
- **NO LEGEND BOX.** Do not draw a square box explaining colors.
- **NO TEXT.** Do not add labels like "Focus Here".
- Keep the original aspect ratio.
`;

const getAiClient = () => {
  const apiKey = process.env.API_KEY;
  if (!apiKey) {
    throw new Error("API Key is missing from environment variables.");
  }
  return new GoogleGenAI({ apiKey });
};

export const analyzeImage = async (base64Data: string, mimeType: string, lang: Language): Promise<string> => {
  try {
    const ai = getAiClient();

    const response = await ai.models.generateContent({
      model: 'gemini-2.5-flash',
      contents: {
        parts: [
          {
            inlineData: {
              data: base64Data,
              mimeType: mimeType,
            },
          },
          {
            text: ANALYSIS_PROMPT[lang],
          },
        ],
      },
      config: {
        systemInstruction: SYSTEM_INSTRUCTION[lang],
        temperature: 0.4,
      },
    });

    return response.text || (lang === 'tr' ? "Analiz sonucu oluÅŸturulamadÄ±." : "Analysis result could not be generated.");
  } catch (error) {
    console.error("Gemini Analysis Error:", error);
    if (error instanceof Error) {
        throw new Error(lang === 'tr' 
            ? `Analiz sÄ±rasÄ±nda bir hata oluÅŸtu: ${error.message}` 
            : `An error occurred during analysis: ${error.message}`);
    }
    throw new Error(lang === 'tr' ? "Analiz sÄ±rasÄ±nda bilinmeyen bir hata oluÅŸtu." : "An unknown error occurred during analysis.");
  }
};

export const generateHeatmap = async (base64Data: string, mimeType: string, lang: Language): Promise<string | null> => {
  try {
    const ai = getAiClient();

    // Using gemini-2.5-flash-image for image editing/generation tasks
    const response = await ai.models.generateContent({
      model: 'gemini-2.5-flash-image',
      contents: {
        parts: [
          {
            inlineData: {
              data: base64Data,
              mimeType: mimeType,
            },
          },
          {
            text: getHeatmapPrompt(lang),
          },
        ],
      },
      // No explicit imageConfig needed as we want the model to infer best output based on input
    });

    // Iterate through parts to find the image part
    if (response.candidates?.[0]?.content?.parts) {
      for (const part of response.candidates[0].content.parts) {
        if (part.inlineData) {
          return part.inlineData.data;
        }
      }
    }
    
    return null;
  } catch (error) {
    console.error("Gemini Heatmap Error:", error);
    // We return null instead of throwing so the main analysis can still succeed even if heatmap fails
    return null;
  }
};
